{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d1152b-4927-47f0-839a-044309cb0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e05f65c-9ca2-40dd-b30f-1eb0b599d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_split import DataSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d422edb-5c2b-488b-b063-e3993665c528",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d269f3af-1441-45fd-8412-8fab2ef5dabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: (train, validation, test) = (0.7, 0.1, 0.2) \n",
      "seedNo.5\n"
     ]
    }
   ],
   "source": [
    "# Trials to exclude for extra verifications\n",
    "trials2drop = ['1_11', '1_8', '1_18', '2_16', '3_30']\n",
    "\n",
    "# dataset ratio (total = 1.0)\n",
    "ratio_test = 0.2\n",
    "ratio_train = 0.7\n",
    "ratio_vali = round(1.0 - ratio_test - ratio_train, 2)\n",
    "print(f'ratio: (train, validation, test) = ({ratio_train}, {ratio_vali}, {ratio_test}) ')\n",
    "\n",
    "# Seed for trial selection\n",
    "seedNo = 5#np.random.randint(0, 2**32)\n",
    "print(f'seedNo.{seedNo}')\n",
    "\n",
    "# Chennel \n",
    "chNo = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d9ee54-aaeb-4a21-8365-487c804cd435",
   "metadata": {},
   "source": [
    "## (1) Load the info (i.e. metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a454c7-2cf2-4994-99ec-6e84f7f594d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels\n",
    "path_meta = '/Volumes/Sandisk_SD/Work/IZFP/Laser/InSignA_campaign2/Code/segmented_data/test'\n",
    "metadf = pd.read_csv('{}/metadata.csv'.format(path_meta), sep = ',', header = 0)\n",
    "# All labels extracted from the metadata\n",
    "y = np.array(metadf.classID, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a0e488-6b43-43e3-9a72-98bdfc0da100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant information\n",
    "classes = list(metadf['class'].unique())# ['noGap', 'Gap0.1', 'Gap0.2', 'Gap0.3', 'noise']\n",
    "classIDs = sorted(list(metadf['classID'].unique())) # make sure the IDs match the class names\n",
    "T_seg = list(metadf['T_seg[ms]'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd5dcb2-baa4-4430-96be-3780689d8020",
   "metadata": {},
   "source": [
    "## (2) Split the trials \n",
    "Trials are split into (a) training set, (b) validation set and (c) test set.\n",
    "With the current version, data split is done in the following steps:\n",
    "\n",
    "* (1) Split all relevant trials into two groups: (a)+(b) and (c) <br>\n",
    "    -> outputs: two lists <br>\n",
    "        * list of trials for train and validation  = (a)+(b) <br>\n",
    "        * list of trials for test = (c)<br> \n",
    "* (2) Split (a)+(b) into (a) and (b) <br>\n",
    "    -> outputs: two lists <br>\n",
    "        * list of trials for train = (a)<br>\n",
    "        * list of trials for validation = (b) <br>\n",
    "* (3) Reset the splitter <br>\n",
    "    -> at the moment a reset is required to get data IDs for the selected trials <br>\n",
    "    => just set splitter.metadf = metadf again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12536a6-fbc3-4ca2-8db3-ce652a55aa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All trials = 60\n",
      "Excluded trials in the metadata = ['2_16' '3_30']\n",
      "Valid trials = 58\n"
     ]
    }
   ],
   "source": [
    "# Sepcify the data size for training / test data\n",
    "# Excluded trials found in the metadata\n",
    "trials2drop_meta = metadf.trial.unique()[np.argwhere(np.isin(metadf.trial.unique(), test_elements=trials2drop)).flatten()]\n",
    "# All valid trials\n",
    "N = len(metadf.trial.unique()) - len(trials2drop_meta)\n",
    "\n",
    "print(f'All trials = {len(metadf.trial.unique())}')\n",
    "print(f'Excluded trials in the metadata = {trials2drop_meta}')\n",
    "print(f'Valid trials = {N}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798c65d-1638-4679-ba19-9c53726244eb",
   "metadata": {},
   "source": [
    "### (2-1) Split into train+vali and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c56f75-e4f6-4029-951e-bc7cd4c03a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSplietter: metadf is modified and dropped some trials!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate\n",
    "splitter = DataSplitter()\n",
    "splitter.metadf = metadf\n",
    "\n",
    "# Return the list of trials\n",
    "trials_rest, trials_test = splitter.trials_split(\n",
    "    ratio=ratio_test, \n",
    "    ret_ID=False,\n",
    "    trials2drop=trials2drop, \n",
    "    seed=seedNo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12447d-3482-4d6d-8abd-87a12520284f",
   "metadata": {},
   "source": [
    "### (2-2) Split into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d2955a0-486a-4a20-b2ab-6842c2e9cb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSplietter: metadf is modified and dropped some trials!\n"
     ]
    }
   ],
   "source": [
    "# Return the list of trials\n",
    "trials_train, trials_vali = splitter.trials_split(\n",
    "    ratio=round(ratio_vali/ratio_train, 5), \n",
    "    ret_ID=False,\n",
    "    trials2drop=trials_test,\n",
    "    seed=seedNo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654db5e2-2d9d-474e-88f1-2a36fec98461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials for training\n",
      "['1_4' '1_7' '1_9' '1_13' '1_16' '1_21' '1_22' '1_23' '1_24' '1_25' '1_26'\n",
      " '1_27' '2_6' '2_8' '2_9' '2_10' '2_12' '2_14' '2_17' '2_23' '2_26' '2_27'\n",
      " '2_30' '2_33' '2_43' '3_4' '3_6' '3_8' '3_10' '3_11' '3_13' '3_17' '3_18'\n",
      " '3_19' '3_20' '3_23' '3_24' '3_25' '3_27' '3_28' '3_32']\n",
      "Trials for validation\n",
      "['1_1' '2_24' '2_29' '3_3' '3_12' '3_16']\n",
      "Trials for test\n",
      "['1_3' '1_6' '2_2' '2_5' '2_22' '2_25' '2_31' '2_41' '3_7' '3_9' '3_26']\n"
     ]
    }
   ],
   "source": [
    "print('Trials for training')\n",
    "print(trials_train)\n",
    "print('Trials for validation')\n",
    "print(trials_vali)\n",
    "print('Trials for test')\n",
    "print(trials_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518922be-77a0-4af8-9a56-3d6b496cacfb",
   "metadata": {},
   "source": [
    "### (2-3) Reset the splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fac45b0b-fe79-4679-a291-212d07b48479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the meta dataframe\n",
    "splitter.metadf = metadf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cee9d2-728f-4462-b9fa-a611e7e97d6f",
   "metadata": {},
   "source": [
    "## (3) Load test set segments\n",
    "-> use **all** segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b439fa04-fa91-441d-b2fe-dd4f05561dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Test ***\n",
      "11 trials, in total = 352 segments\n",
      "trials = ['1_3' '1_6' '2_2' '2_5' '2_22' '2_25' '2_31' '2_41' '3_7' '3_9' '3_26']\n",
      "segments = [32 33 34 35 36]...\n"
     ]
    }
   ],
   "source": [
    "id_test = splitter.get_dataIDs(trials_test)\n",
    "\n",
    "print('*** Test ***')\n",
    "print(f'{len(trials_test)} trials, in total = {len(id_test)} segments')\n",
    "print(f'trials = {trials_test}')\n",
    "print(f'segments = {id_test[:5]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8f738-a5f5-4374-b97d-443db513f482",
   "metadata": {},
   "source": [
    "## (4) Load validation set segments\n",
    "-> use **all** segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "786f91f1-79f4-4673-8114-238d811ab059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Validation ***\n",
      "6 trials, in total = 192 segments\n",
      "trials = ['1_1' '2_24' '2_29' '3_3' '3_12' '3_16']\n",
      "segments = [0 1 2 3 4]...\n"
     ]
    }
   ],
   "source": [
    "id_vali = splitter.get_dataIDs(trials_vali)\n",
    "\n",
    "print('*** Validation ***')\n",
    "print(f'{len(trials_vali)} trials, in total = {len(id_vali)} segments')\n",
    "print(f'trials = {trials_vali}')\n",
    "print(f'segments = {id_vali[:5]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36d3cd7-d304-4f6f-b4d2-bf5709665305",
   "metadata": {},
   "source": [
    "## (4) Load training set segments\n",
    "-> select segments randomly, while keeping the same data size for all classes <br>\n",
    "Why? Because some classes have more valid segments than other classes. <br>\n",
    "If you want to use all training segments, repeat the same procedure as (3) and (4). <br>\n",
    "(Don't forget to shuffle the output though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eea198a-8758-45f5-a0ad-050d9bb6c466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 41 trials:\n",
      "['1_4' '1_7' '1_9' '1_13' '1_16' '1_21' '1_22' '1_23' '1_24' '1_25' '1_26'\n",
      " '1_27' '2_6' '2_8' '2_9' '2_10' '2_12' '2_14' '2_17' '2_23' '2_26' '2_27'\n",
      " '2_30' '2_33' '2_43' '3_4' '3_6' '3_8' '3_10' '3_11' '3_13' '3_17' '3_18'\n",
      " '3_19' '3_20' '3_23' '3_24' '3_25' '3_27' '3_28' '3_32'] \n",
      "\n",
      "Total segments selected = 150\n",
      "class 0 = 50, segs = [ 195  246 1553  354  704  686  398  934 1048  626]...\n",
      "class 1 = 50, segs = [ 790 1026  786   93 1807  779  176 1636 1820  356]...\n",
      "class 2 = 50, segs = [ 447 1898 1571  332 1539  589  694 1729  640  181]...\n"
     ]
    }
   ],
   "source": [
    "# (1) Select some segemens randomly\n",
    "# -> output is \"sorted\" according to the classes (segments of class 0 appear at the beginning) \n",
    "id_train = splitter.select_segments_balanced_class(trials_train, N_seg_class = 50, seed=30)\n",
    "\n",
    "# (2) Shuffle, if necessary \n",
    "rng = np.random.default_rng(20)\n",
    "id_train = rng.permutation(id_train)\n",
    "\n",
    "# Training set\n",
    "print(f'From {len(trials_train)} trials:') \n",
    "print(f'{trials_train} \\n')\n",
    "print(f'Total segments selected = {len(id_train)}')\n",
    "\n",
    "for curr_ID in classIDs:\n",
    "    print(f'class {curr_ID} = {len(np.argwhere(y[id_train]==curr_ID))}, segs = {id_train[curr_ID*50:curr_ID*50+10]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a696f7-b3bf-4f32-88ce-e85c25322eaa",
   "metadata": {},
   "source": [
    "## (5) Load the input data for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e4a4aee-116c-46fb-b412-c91e66a27dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signal(fileID, path, chNo,\n",
    "                *args, **kwargs\n",
    "                ):\n",
    "    # (1) Load\n",
    "    fname = f'ch{chNo}/data_{fileID[0]}.npy'\n",
    "    data = np.load(f'{path}/{fname}')\n",
    "    # (2) you can do any preprocessing here, just for an example sake, I just cut the signal here\n",
    "    data_proc = data[:1000]\n",
    "    return data_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b29a9a-0f0c-43f8-affb-ff1fe54e99ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data are loaded!\n"
     ]
    }
   ],
   "source": [
    "# Data path\n",
    "path = '/Volumes/Sandisk_SD/Work/IZFP/Laser/InSignA_campaign2/Code/segmented_data/test'\n",
    "\n",
    "# Loading\n",
    "X_train = np.apply_along_axis(\n",
    "    func1d = load_signal, \n",
    "    axis = 0, \n",
    "    arr = id_train[np.newaxis, ...], \n",
    "    path = path, \n",
    "    chNo = chNo, \n",
    ")\n",
    "\n",
    "X_vali = np.apply_along_axis(\n",
    "    func1d = load_signal, \n",
    "    axis = 0, \n",
    "    arr = id_vali[np.newaxis, ...], \n",
    "    path = path, \n",
    "    chNo = chNo, \n",
    ")\n",
    "\n",
    "X_test = np.apply_along_axis(\n",
    "    func1d = load_signal, \n",
    "    axis = 0, \n",
    "    arr = id_test[np.newaxis, ...], \n",
    "    path = path, \n",
    "    chNo = chNo, \n",
    ")\n",
    "\n",
    "print('Input data are loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f946614-f79b-4504-ac6e-1ac8adeae0d6",
   "metadata": {},
   "source": [
    "## (6) Load the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5082a208-8515-4765-bd3d-238ac0e2617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[id_train]\n",
    "y_vali = y[id_vali]\n",
    "y_test = y[id_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c52cd111-bc8a-41a6-9e29-68e63981557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0, 1, 1, 1, 2, 0, 2, 2, 1, 2, 0, 2, 2, 2, 2, 0, 2, 2,\n",
       "       1, 2, 2, 0, 2, 0, 0, 0, 1, 2, 2, 2, 2, 0, 1, 0, 0, 2, 1, 2, 0, 1,\n",
       "       2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1,\n",
       "       2, 2, 1, 2, 0, 1, 2, 2, 1, 1, 0, 1, 0, 1, 0, 2, 1, 2, 0, 2, 2, 2,\n",
       "       1, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 2, 0, 0, 2,\n",
       "       2, 1, 0, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2,\n",
       "       2, 0, 2, 1, 2, 2, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the labels of the training set\n",
    "y_train[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5d4cb-137c-459e-9477-36247878d432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
